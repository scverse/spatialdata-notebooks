{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f941ac7-6cd1-4087-ba7b-15a3d2cabf77",
   "metadata": {},
   "source": [
    "# Use landmark annotations to align multiple -omics layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee45520",
   "metadata": {},
   "source": [
    "We will align a Xenium and a Visium datasets for a breast cancer dataset.\n",
    "\n",
    "We will:\n",
    "1. load the data from Zarr;\n",
    "2. add landmark annotations to the data using napari;\n",
    "3. find an affine similarity transformation that aligns the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ecb39a",
   "metadata": {},
   "source": [
    "## Loading the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc11fee9",
   "metadata": {},
   "source": [
    "You can download the data from here: [Xenium dataset](https://s3.embl.de/spatialdata/spatialdata-sandbox/xenium_rep1_io.zip), [Visium dataset](https://s3.embl.de/spatialdata/spatialdata-sandbox/visium_associated_xenium_io.zip). Please rename the files to `xenium.zarr` and `visium.zarr` and place them in the same folder as this notebook (or use symlinks to make the data accessible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33ec76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spatialdata as sd\n",
    "\n",
    "# from napari_spatialdata import Interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cb18bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xenium_sdata = sd.read_zarr(\"xenium.zarr\")\n",
    "xenium_sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b923aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "visium_sdata = sd.read_zarr(\"visium.zarr\")\n",
    "visium_sdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa12f3a",
   "metadata": {},
   "source": [
    "Let's visualize the data with napari.\n",
    "\n",
    "*Note: we are working with the napari developers to improve performance when visualizing large collections of geometries. For the sake of this example let's just show the Xenium and Visium images.*"
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "interactive = Interactive([visium_sdata, xenium_sdata])\n",
    "interactive.add_element(element=\"morphology_focus\", element_coordinate_system=\"global\")\n",
    "interactive.add_element(element=\"morphology_mip\", element_coordinate_system=\"global\")\n",
    "interactive.add_element(element=\"CytAssist_FFPE_Human_Breast_Cancer_full_image\", element_coordinate_system=\"global\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a0ba65ae2273906"
  },
  {
   "cell_type": "markdown",
   "id": "0ec2165b",
   "metadata": {},
   "source": [
    "Here is a screenshot of the napari viewer. The images are not spatially aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c30be-9aa7-4d89-92f6-0427a4ae3f28",
   "metadata": {},
   "source": [
    "![](attachments/landmarks0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd50e8fe",
   "metadata": {},
   "source": [
    "## Adding landmark annotations\n",
    "\n",
    "Let's add some landmarks annotations using napari. We will add 3 landmarks to the Visium image to mark recognizable anatomical structures. We will then add, 3 landmarks to the Xenium image to the corresponding anatomical structures, in the same order. One can add more than 3 landmarks per image, as long as the order match between the images.\n",
    "\n",
    "This is the procedure to annotate and save the landmark locations (shown in the GIF):\n",
    "1. open `napari` with `Interactive()` from `napari_spatialdata`\n",
    "2. create a new Points layer in napari\n",
    "3. (optional) rename the layer\n",
    "4. (optional) change the color and points size for easier visualization\n",
    "5. click to add the annotation point\n",
    "6. (optional) use the `napari` functions to move/delete points\n",
    "7. save the annotation to the `SpatialData` object by pressing `Shift + E` (if you called `Interactive()` passing multiple `SpatialData` objects, the annotations will be saved to one of them).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de40a8c6-4e84-4595-816a-2f442f5be320",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](attachments/landmarks1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890a6dc",
   "metadata": {},
   "source": [
    "For reproducibility, we hardcoded in this notebook the landmark annotations for the Visium and Xenium data. We will add them to the respective `SpatialData` objects, both in-memory and on-disk, as if they were were saved with napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ba021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialdata.models import ShapesModel\n",
    "\n",
    "visium_landmarks = ShapesModel.parse(\n",
    "    np.array([[10556.699, 7829.764], [13959.155, 13522.025], [10621.200, 17392.116]]), geometry=0, radius=500\n",
    ")\n",
    "visium_sdata[\"visium_landmarks\"] = visium_landmarks\n",
    "\n",
    "xenium_landmarks = ShapesModel.parse(\n",
    "    np.array([[9438.385, 13933.017], [24847.866, 5948.002], [34082.584, 15234.235]]), geometry=0, radius=500\n",
    ")\n",
    "xenium_sdata[\"xenium_landmarks\"] = xenium_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b382d7",
   "metadata": {},
   "source": [
    "## Finding the affine similarity transformation\n",
    "\n",
    "### Aligning the images\n",
    "\n",
    "We will now use the landmarks to find a similarity affine transformations that maps the Visium image onto the Xenium one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6dff4-ff07-495d-b29f-1e20e3f49d84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialdata.transformations import (\n",
    "    align_elements_using_landmarks,\n",
    "    get_transformation_between_landmarks,\n",
    ")\n",
    "\n",
    "affine = get_transformation_between_landmarks(\n",
    "    references_coords=xenium_sdata[\"xenium_landmarks\"], moving_coords=visium_sdata[\"visium_landmarks\"]\n",
    ")\n",
    "affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5793e680",
   "metadata": {},
   "source": [
    "To apply the transformation to the Visium data, we will use the `align_elements_using_landmarks` function. This function internally calls `get_transformation_between_landmarks` and adds the transformation to the `SpatialData` object. It then returns the same affine matrix.\n",
    "\n",
    "More specifically, we will align the image `CytAssist_FFPE_Human_Breast_Cancer_full_image` from the Visium data onto the `morphology_mip` image from the Xenium data. Both images live in the `\"global\"` coordinate system (you can see this information by printing `xenium_sdata` and `visium_sdata`). The images are not aligned in the `\"global\"` coordinate system, and we want them to be aligned in a new coordinate system called `\"aligned\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71718a2",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "affine = align_elements_using_landmarks(\n",
    "    references_coords=xenium_sdata[\"xenium_landmarks\"],\n",
    "    moving_coords=visium_sdata[\"visium_landmarks\"],\n",
    "    reference_element=xenium_sdata[\"morphology_mip\"],\n",
    "    moving_element=visium_sdata[\"CytAssist_FFPE_Human_Breast_Cancer_full_image\"],\n",
    "    reference_coordinate_system=\"global\",\n",
    "    moving_coordinate_system=\"global\",\n",
    "    new_coordinate_system=\"aligned\",\n",
    ")\n",
    "affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915cc3a2-47e5-4ec7-ac6c-8526dcbe7f6b",
   "metadata": {},
   "source": [
    "Now the Visium and the Xenium images are aligned in the `aligned` coordinate system via an affine transformation which rotates, scales and translates the data. We can see this in napari."
   ]
  },
  {
   "cell_type": "raw",
   "source": [
    "interactive = Interactive([visium_sdata, xenium_sdata])\n",
    "interactive.add_element(element=\"CytAssist_FFPE_Human_Breast_Cancer_full_image\", element_coordinate_system=\"aligned\")\n",
    "interactive.add_element(element=\"morphology_mip\", element_coordinate_system=\"global\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fac16daf2d8eb14b"
  },
  {
   "cell_type": "markdown",
   "id": "f49d8442-0501-4a9a-965e-c86040c33758",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](attachments/landmarks2.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5e715-84f5-4457-ac4a-e1addd9fb355",
   "metadata": {},
   "source": [
    "Note: the above operation doesn't modify the data, but it just modifies the alignment metadata which define how elements are positioned inside coordinate system. Both images are mapped to the `global` coordinate system (in which they are not aligned) and in the `aligned` coordinate system, where they overlap. In napari you can choose which coordinate system to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d657aa19-8443-447c-828c-b91b5cb6cf75",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](attachments/landmarks3.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d318e03-8c04-4cc3-9da9-0e56119def9f",
   "metadata": {},
   "source": [
    "### Aligning the rest of the elements\n",
    "\n",
    "So far we mapped the Visium image onto the Xenium image in the `aligned` coordinate system. The rest of the elements are still not aligned. To correct for this we will append the affine transformation calculated above to each transformation for each elements.\n",
    "\n",
    "*Note: this handling of transformation will become more ergonomics in the next code release, removing the need to manually append the transformation as we are doing below. We will update this notebook with the new approach.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c442fdb-94a9-488c-8d87-cfcc109f9388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialdata import SpatialData\n",
    "from spatialdata.transformations import (\n",
    "    BaseTransformation,\n",
    "    Sequence,\n",
    "    get_transformation,\n",
    "    set_transformation,\n",
    ")\n",
    "\n",
    "\n",
    "def postpone_transformation(\n",
    "    sdata: SpatialData,\n",
    "    transformation: BaseTransformation,\n",
    "    source_coordinate_system: str,\n",
    "    target_coordinate_system: str,\n",
    "):\n",
    "    for element_type, element_name, element in sdata._gen_elements():\n",
    "        old_transformations = get_transformation(element, get_all=True)\n",
    "        if source_coordinate_system in old_transformations:\n",
    "            old_transformation = old_transformations[source_coordinate_system]\n",
    "            sequence = Sequence([old_transformation, transformation])\n",
    "            set_transformation(element, sequence, target_coordinate_system)\n",
    "\n",
    "\n",
    "postpone_transformation(\n",
    "    sdata=visium_sdata,\n",
    "    transformation=affine,\n",
    "    source_coordinate_system=\"global\",\n",
    "    target_coordinate_system=\"aligned\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328673d-0c87-4b29-b6d7-d7609b96d394",
   "metadata": {},
   "source": [
    "Let's visualize the result of the alignment with napari."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7d0e066-2373-4608-a03c-ff91064c79aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "Interactive([visium_sdata, xenium_sdata])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b443cd-9f35-45f8-9f55-9ec108b0b1d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](attachments/landmarks4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9277db",
   "metadata": {},
   "source": [
    "### Saving the alignment back to Zarr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e98374c-85cd-45ad-ac62-b2bc075c9631",
   "metadata": {},
   "source": [
    "We will now save the transformations to disk. Notice that this is a lightweight operation because we are just mofiying the objects metadata, not transforming the actual data. This is useful when dealing with large images and when one may need to reiterate multiple steps of landmark-based alignment in order to improve the spatial agreement of the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474410bd-2d02-45c1-b073-eba1152ab615",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from spatialdata import save_transformations\n",
    "\n",
    "save_transformations(visium_sdata)\n",
    "save_transformations(xenium_sdata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "spatialdata_310",
   "language": "python",
   "display_name": "spatialdata_310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "830f4db94a7e048b072d559f6337879e869a5f16cc1fbf14c7dab0d06a5037ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
